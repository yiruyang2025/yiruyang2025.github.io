---
layout: post
title: Benchmarks for Speech Processing Post-training - 25
date: 2025-05-01
description: ðŸ¥¥
categories: AI/ML
thumbnail: assets/img/9.jpg
images:
  lightbox2: true
  photoswipe: true
  spotlight: true
  venobox: true
---

Welcome âœ¨!  <br><br>

This one is actually a little bit difficult for me to write, with aging, my short-term memory is no longer as good as it used to be :)<br><br>


# 1.Introduction<br><br>

Let's discuss the main benchmarking metrics used in current industry practice.<br><br><br><br>



# 2. Recent Benchmark Frameworks<br><br>

pending<br><br>

## 2.1 Evaluation Metrics for Text-to-Speech (TTS)



| Year | Metric | Description | Typical Range |
|------|--------|-------------|---------------|
| 2023 | **VoiceMOS (Zero-shot)** | Out-of-domain MOS prediction challenge metric | 1â€“5 (â†‘) |
| 2024 | **MOSA-Net** | Multi-objective no-reference (quality + intelligibility + distortion) | metric-specific (â†‘) |
| 2024 | **DNSMOS-Pro** | Lightweight on-device variant of DNSMOS | 1â€“5 (â†‘) |


<br><br><br><br>

## 2.2 Evaluation Metrics for Voice Conversion (VC)

| Year | Metric | Description | Typical Range |
|------|--------|-------------|---------------|
| 2023 | **G-MOS** | Cross-domain crowd MOS (VoiceMOSâ€™23) | 1â€“5 (â†‘) |
| 2024 | **SASV-EER** | Joint speaker-&-spoof error rate (SASV Challenge) | 0â€“1 (â†“) |

<br><br><br><br>

## 2.3 Speech-to-Speech Translation (S2ST) Benchmarks

| Year | Metric | Description | Typical Range |
|------|--------|-------------|---------------|
| 2023 | **ASR-BLEU** | BLEU on ASR transcripts of output speech | 0â€“100 (â†‘) |
| 2024 | **BLASER 2.0** | Reference-free cross-modal quality metric | 0â€“1 (â†‘) |



<br><br><br><br>


# 3.Specific Evaluation Frameworks for Disabled Users<br><br><br><br>















