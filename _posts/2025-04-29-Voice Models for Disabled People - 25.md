---
layout: post
title: Voice Models for Disabled People - 25
date: 2025-04-29
description: ü••
categories: AI/ML
thumbnail: assets/img/9.jpg
images:
  lightbox2: true
  photoswipe: true
  spotlight: true
  venobox: true
---

Welcome ‚ú®! 

Let's Start with Hearing Assistance<br><br><br><br>

# 0. Let's have some taste of Background Knowledge First!:)<br><br>


Voice models are AI systems that process or generate human speech.Core AI Techniques used are listed as below:

| Technique                   | Purpose                                                              | Example Models                |
|----------------------------|----------------------------------------------------------------------|-------------------------------|
| **RNN / LSTM**             | Early sequence modeling in ASR & TTS                                 | DeepSpeech (2014), Tacotron 1 |
| **CNNs**                   | Feature extraction from spectrograms                                | WaveGlow                      |
| **Transformers**           | Parallel processing, great for long-range speech dependencies        | SpeechT5, Whisper, FastSpeech2|
| **Diffusion Models**       | High-quality, controllable generation (recent TTS trend)              | Grad-TTS, FastDiff            |
| **Self-supervised Pretraining** | Efficient training on large unlabeled datasets                     | wav2vec 2.0, HuBERT            |

<br><br><br><br>

Core Evolution of Voice Models:
| Year | Milestone                        | Model / Paper                                                     |
|------|----------------------------------|-------------------------------------------------------------------|
| 2014 | End-to-end ASR                   | DeepSpeech ([Hannun et al.](https://arxiv.org/abs/1412.5567))     |
| 2017 | Tacotron (neural TTS)            | Tacotron ([Wang et al.](https://arxiv.org/abs/1703.10135))        |
| 2019 | Real-time voice synthesis        | FastSpeech ([Ren et al.](https://arxiv.org/abs/1905.09263))       |
| 2020 | Self-supervised speech learning | wav2vec 2.0 ([Baevski et al.](https://arxiv.org/abs/2006.11477))  |
| 2021 | Multilingual speech models       | Whisper (OpenAI, 2022)                                            |
| 2023‚Äì2024 | Diffusion-based TTS              | FastDiff ([Huang et al.](https://arxiv.org/abs/2305.10973))        |

<br><br><br><br>

# 1. Voice Models in Industry<br><br>

**1.1** Google Sound Amplifier, 2019
  - [Sound Amplifier](https://play.google.com/store/apps/details?id=com.google.android.accessibility.soundamplifier)
  - [AudioEffect API](https://developer.android.com/reference/android/media/audiofx/AudioEffect)<br><br>
 
**1.2** Rogervoice, 2014
  - [Rogervoice](https://rogervoice.com/)
  - [GitHub repository](https://github.com/rogervoice)<br><br>

**1.3** Pedius, 2013
  - [Pedius](https://www.pedius.org/zh/zhuye/)<br><br><br><br>



# 2. Model Traning<br><br>

**2.1** Pre-training with text
  - 2023. [Toward Joint Language Modeling for Speech Units and Text](https://arxiv.org/abs/2310.08715)
  - 2024. [Spirit LM: Interleaved Spoken and Written Language Model](https://arxiv.org/abs/2402.05755)
  - 2024. [OpenAI - Navigating the Challenges and Opportunities of Synthetic Voices](https://openai.com/index/navigating-the-challenges-and-opportunities-of-synthetic-voices/)
  - 2022. [Dialogue GSLM](https://arxiv.org/abs/2203.16502)<br><br><br><br>





# 3. Recent Academic Advances in Voice Modeling<br><br>

- 2023, [Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00618/118854)
- 2014, [Deep Speech: Scaling up end-to-end speech recognition](https://arxiv.org/abs/1412.5567)<br><br><br><br>




# 4. Products for Disabled People<br><br><br><br>





# 5. The Business Ecosystem<br><br><br><br>





# 6. Speech Processing Labs Worldwide<br><br><br><br>




# 7. Others<br><br>

**7.1** ASR: Automatic Speech Recognition
  - [Whisper - OpenAI](https://github.com/openai/whisper)


**7.2** TTS: Text-to-Speech
  - [Tacotron2 - Google](https://github.com/Rayhane-mamah/Tacotron-2)


**7.3** Voice Cloning / Real-Time TTS
  - [ElevenLabs](https://elevenlabs.io/)
  - [Real-Time Voice Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)


**7.4** Emotion & Multi-speaker TTS
  - [ChatTTS - ‰∏≠Ëã±ÂØπËØù](https://github.com/2noise/ChatTTS)
  - [OpenVoice](https://github.com/myshell-ai/OpenVoice)

**7.5** Audio Agents
  - [GPT-4 Turbo with Audio](https://openai.com/gpt-4-turbo/)
  - [FunAudioLLM](https://github.com/FunAudioLLM)  <br><br><br><br>








